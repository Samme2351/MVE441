{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from tqdm import tqdm\n",
    "\n",
    "#features = [f\"V{x}\" for x in range(1,2000)]\n",
    "df = pd.read_csv('Data/TCGAdata.txt', sep=\" \" ,header=0)\n",
    "labels_df = pd.read_csv('Data/TCGAlabels', sep=\" \" ,header=0)\n",
    "\n",
    "#Set max number of components for PCA\n",
    "max_num_components = 25\n",
    "\n",
    "num_components_range = range(1, max_num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processes the data by splitting and normalizing \n",
    "def pre_process(data, labels, train_size):\n",
    "    #Split data into training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, labels_df.values.ravel(), test_size=1-train_size, random_state=42)\n",
    "    \n",
    "    #Standardize the rows (transposing as fit_transform standardizes along columns)\n",
    "    #Scale after split to avoid data leakage\n",
    "    scaler = StandardScaler()\n",
    "    X_train = pd.DataFrame(np.transpose(scaler.fit_transform(X_train.transpose())), columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(np.transpose(scaler.fit_transform(X_test.transpose())), columns=X_test.columns)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNN PCA\n",
    "\n",
    "def KNN_PCA(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    KNN_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "    # Loop over different numbers of components\n",
    "    for n_components in tqdm(num_components_range):\n",
    "\n",
    "        #PCA\n",
    "\n",
    "        KNN_pipeline = make_pipeline(PCA(n_components=n_components), KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "        KNN_scores = cross_val_score(KNN_pipeline, X_train, y_train, cv=5)\n",
    "        KNN_mean_score = KNN_scores.mean()\n",
    "\n",
    "        #KNN_mean_scores.append(KNN_mean_score)\n",
    "        KNN_mean_scores[n_components] = KNN_mean_score\n",
    "\n",
    "    KNN_optimal_n_components = np.where(KNN_mean_scores==KNN_mean_scores.max())[0][0]+1\n",
    "    cross_val_err = 1 - max(KNN_mean_scores)\n",
    "\n",
    "    print(\"KNN optimal number of PCA components:\", KNN_optimal_n_components)\n",
    "\n",
    "    opt_pipeline = make_pipeline(PCA(n_components=KNN_optimal_n_components), KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "    opt_pipeline.fit(X_train, y_train)\n",
    "    train_pred = opt_pipeline.predict(X_train)\n",
    "    train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "    test_pred = opt_pipeline.predict(X_test)\n",
    "    test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"Cross val err: \", cross_val_err)\n",
    "    print(\"Train err: \", train_error)\n",
    "    print(\"Test err: \", test_error)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNN features\n",
    "\n",
    "def KNN_features(X_train, X_test, y_train, y_test):\n",
    "    max_num_features = 50\n",
    "\n",
    "    num_features = range(1, max_num_features)\n",
    "    KNN_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "    # Loop over different numbers of features\n",
    "    for k in tqdm(num_features):\n",
    "\n",
    "        feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "        X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "        KNN_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "        KNN_mean_score = KNN_scores.mean()\n",
    "\n",
    "        KNN_mean_scores[k] = KNN_mean_score\n",
    "\n",
    "        #KNN_mean_scores.append(KNN_mean_score)\n",
    "\n",
    "    KNN_optimal_k_features = np.where(KNN_mean_scores==KNN_mean_scores.max())[0][0]+1\n",
    "    cross_val_err = 1 - max(KNN_mean_scores)\n",
    "\n",
    "    print(\"KNN optimal number of features:\", KNN_optimal_k_features)\n",
    "\n",
    "    feature_selector = SelectKBest(f_classif, k=KNN_optimal_k_features)\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "    # Get the indices of the selected features\n",
    "    selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "    # Get the names of the most predictive features\n",
    "    selected_features = X_train.columns[selected_feature_indices]\n",
    "    print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "\n",
    "    train_pred = model.predict(X_train_selected)\n",
    "    train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "    test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "    test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"Cross val err: \", cross_val_err)\n",
    "    print(\"Train err: \", train_error)\n",
    "    print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVC PCA\n",
    "def SVC_PCA(X_train, X_test, y_train, y_test):\n",
    "    SVC_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "    #num_components_range = range(1, max_num_components)\n",
    "\n",
    "    # Loop over different numbers of components\n",
    "    for n_components in tqdm(num_components_range):\n",
    "\n",
    "        #PCA\n",
    "\n",
    "        SVC_pipeline = make_pipeline(PCA(n_components=n_components), SVC())\n",
    "\n",
    "        SVC_scores = cross_val_score(SVC_pipeline, X_train, y_train, cv=5)\n",
    "        SVC_mean_score = SVC_scores.mean()\n",
    "\n",
    "        #SVC_mean_scores.append(SVC_mean_score)\n",
    "        SVC_mean_scores[n_components] = SVC_mean_score\n",
    "\n",
    "    SVC_optimal_n_components = np.where(SVC_mean_scores==SVC_mean_scores.max())[0][0]+1\n",
    "    cross_val_err = 1 - max(SVC_mean_scores)\n",
    "\n",
    "    print(\"SVC optimal number of PCA components:\", SVC_optimal_n_components)\n",
    "\n",
    "    opt_pipeline = make_pipeline(PCA(n_components=SVC_optimal_n_components), SVC())\n",
    "\n",
    "    opt_pipeline.fit(X_train, y_train)\n",
    "    train_pred = opt_pipeline.predict(X_train)\n",
    "    train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "    test_pred = opt_pipeline.predict(X_test)\n",
    "    test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"Cross val err: \", cross_val_err)\n",
    "    print(\"Train err: \", train_error)\n",
    "    print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVC features\n",
    "\n",
    "def SVC_features(X_train, X_test, y_train, y_test):\n",
    "    max_num_features = 50\n",
    "    num_features = range(1, max_num_features)\n",
    "    SVC_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "    # Loop over different numbers of components\n",
    "    for k in tqdm(num_features):\n",
    "\n",
    "        feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "        X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "\n",
    "        model = SVC()\n",
    "\n",
    "        SVC_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "        SVC_mean_score = SVC_scores.mean()\n",
    "\n",
    "        #SVC_mean_scores.append(SVC_mean_score)\n",
    "        SVC_mean_scores[k] = SVC_mean_score\n",
    "\n",
    "\n",
    "    SVC_optimal_k_features = np.where(SVC_mean_scores==SVC_mean_scores.max())[0][0]+1\n",
    "    cross_val_err = 1 - max(SVC_mean_scores)\n",
    "\n",
    "    print(\"SVC optimal number of features:\", SVC_optimal_k_features)\n",
    "\n",
    "    feature_selector = SelectKBest(f_classif, k=SVC_optimal_k_features)\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Get the indices of the selected features\n",
    "    selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "    # Get the names of the most predictive features\n",
    "    selected_features = X_train.columns[selected_feature_indices]\n",
    "    print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "\n",
    "    train_pred = model.predict(X_train_selected)\n",
    "    train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "    test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "    test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"Cross val err: \", cross_val_err)\n",
    "    print(\"Train err: \", train_error)\n",
    "    print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Logistic regression PCA\n",
    "\n",
    "def LR_PCA(X_train, X_test, y_train, y_test):\n",
    "    LR_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "    #num_components_range = range(1, 25)\n",
    "\n",
    "    # Loop over different numbers of components\n",
    "    for n_components in tqdm(num_components_range):\n",
    "\n",
    "        #PCA\n",
    "\n",
    "        LR_pipeline = make_pipeline(PCA(n_components=n_components), LogisticRegression(random_state=16, max_iter=10000))\n",
    "\n",
    "        LR_scores = cross_val_score(LR_pipeline, X_train, y_train, cv=5)\n",
    "        LR_mean_score = LR_scores.mean()\n",
    "\n",
    "        #LR_mean_scores.append(LR_mean_score)\n",
    "        LR_mean_scores[n_components] = LR_mean_score\n",
    "\n",
    "    LR_optimal_n_components = np.where(LR_mean_scores==LR_mean_scores.max())[0][0]+1\n",
    "    cross_val_err = 1 - max(LR_mean_scores)\n",
    "\n",
    "    print(\"KNN optimal number of PCA components:\", LR_optimal_n_components)\n",
    "\n",
    "    opt_pipeline = make_pipeline(PCA(n_components=LR_optimal_n_components), LogisticRegression(random_state=16, max_iter=10000))\n",
    "\n",
    "    opt_pipeline.fit(X_train, y_train)\n",
    "    train_pred = opt_pipeline.predict(X_train)\n",
    "    train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "    test_pred = opt_pipeline.predict(X_test)\n",
    "    test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"Cross val err: \", cross_val_err)\n",
    "    print(\"Train err: \", train_error)\n",
    "    print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Logistic Regression features\n",
    "\n",
    "def LR_features(X_train, X_test, y_train, y_test):\n",
    "    max_num_features = 100\n",
    "    num_features = range(1, max_num_features)\n",
    "    LR_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "    # Loop over different numbers of components\n",
    "    for k in tqdm(num_features):\n",
    "\n",
    "        feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "        X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "\n",
    "        model = LogisticRegression(random_state=16, max_iter=10000)\n",
    "\n",
    "        LR_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "        LR_mean_score = LR_scores.mean()\n",
    "\n",
    "        #LR_mean_scores.append(LR_mean_score)\n",
    "        LR_mean_scores[k] = LR_mean_score\n",
    "\n",
    "    LR_optimal_k_features = np.where(LR_mean_scores==LR_mean_scores.max())[0][0]+1\n",
    "    cross_val_err = 1 - max(LR_mean_scores)\n",
    "\n",
    "    print(\"LR optimal number of features:\", LR_optimal_k_features)\n",
    "\n",
    "    feature_selector = SelectKBest(f_classif, k=LR_optimal_k_features)\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Get the indices of the selected features\n",
    "    selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "    # Get the names of the most predictive features\n",
    "    selected_features = X_train.columns[selected_feature_indices]\n",
    "    print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "    train_pred = model.predict(X_train_selected)\n",
    "    train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "    test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "    test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "    print(\"Cross val err: \", cross_val_err)\n",
    "    print(\"Train err: \", train_error)\n",
    "    print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 99/99 [01:23<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR optimal number of features: 100\n",
      "Most predictive features: Index(['V3', 'V16', 'V18', 'V29', 'V30', 'V35', 'V63', 'V64', 'V68', 'V72',\n",
      "       'V83', 'V87', 'V200', 'V217', 'V227', 'V274', 'V289', 'V307', 'V308',\n",
      "       'V350', 'V394', 'V418', 'V462', 'V464', 'V475', 'V494', 'V507', 'V539',\n",
      "       'V541', 'V544', 'V568', 'V578', 'V600', 'V627', 'V657', 'V658', 'V673',\n",
      "       'V687', 'V691', 'V730', 'V803', 'V818', 'V845', 'V850', 'V855', 'V889',\n",
      "       'V922', 'V982', 'V1005', 'V1033', 'V1066', 'V1071', 'V1097', 'V1098',\n",
      "       'V1101', 'V1102', 'V1126', 'V1152', 'V1173', 'V1193', 'V1203', 'V1206',\n",
      "       'V1218', 'V1234', 'V1249', 'V1256', 'V1263', 'V1290', 'V1293', 'V1443',\n",
      "       'V1478', 'V1517', 'V1530', 'V1533', 'V1549', 'V1575', 'V1580', 'V1583',\n",
      "       'V1635', 'V1654', 'V1657', 'V1673', 'V1697', 'V1719', 'V1744', 'V1772',\n",
      "       'V1787', 'V1799', 'V1812', 'V1813', 'V1827', 'V1829', 'V1846', 'V1868',\n",
      "       'V1871', 'V1877', 'V1881', 'V1882', 'V1936', 'V1971'],\n",
      "      dtype='object')\n",
      "Cross val err:  0.003960396039603964\n",
      "Train err:  0.0\n",
      "Test err:  0.00692041522491349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samme/.local/lib/python3.10/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Run everything with 70/30 split\n",
    "X_train, X_test, y_train, y_test = pre_process(df, labels_df, 0.7)\n",
    "\n",
    "KNN_PCA(X_train, X_test, y_train, y_test)\n",
    "KNN_features(X_train, X_test, y_train, y_test)\n",
    "SVC_PCA(X_train, X_test, y_train, y_test)\n",
    "SVC_features(X_train, X_test, y_train, y_test)\n",
    "LR_PCA(X_train, X_test, y_train, y_test)\n",
    "LR_features(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2309\n"
     ]
    }
   ],
   "source": [
    "#Run everything with 80/20 split\n",
    "X_train, X_test, y_train, y_test = pre_process(df, labels_df, 0.8)\n",
    "\n",
    "KNN_PCA(X_train, X_test, y_train, y_test)\n",
    "KNN_features(X_train, X_test, y_train, y_test)\n",
    "SVC_PCA(X_train, X_test, y_train, y_test)\n",
    "SVC_features(X_train, X_test, y_train, y_test)\n",
    "LR_PCA(X_train, X_test, y_train, y_test)\n",
    "LR_features(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run everything with 90/10 split\n",
    "X_train, X_test, y_train, y_test = pre_process(df, labels_df, 0.9)\n",
    "\n",
    "KNN_PCA(X_train, X_test, y_train, y_test)\n",
    "KNN_features(X_train, X_test, y_train, y_test)\n",
    "SVC_PCA(X_train, X_test, y_train, y_test)\n",
    "SVC_features(X_train, X_test, y_train, y_test)\n",
    "LR_PCA(X_train, X_test, y_train, y_test)\n",
    "LR_features(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Part 2 Theme 2 mislabeling\n",
    "\n",
    "mislabel_fraction = 0.2\n",
    "\n",
    "def mislabel(mislabel_fraction, y_train):\n",
    "    labels = set(labels_df[\"x\"])\n",
    "\n",
    "    num_samples = len(y_train)\n",
    "    num_mislabels = int(mislabel_fraction * num_samples)\n",
    "    mislabel_indices = np.random.choice(num_samples, num_mislabels, replace=False)\n",
    "\n",
    "    y_train_noise = y_train.copy()\n",
    "\n",
    "    for i in mislabel_indices:\n",
    "        correct = y_train[i]\n",
    "        y_train_noise[i] = np.random.choice(list(labels - set([correct])))\n",
    "    \n",
    "    return y_train_noise\n",
    "\n",
    "X_train, X_test, y_train, y_test = pre_process(df, labels_df, 0.7)\n",
    "y_train_noise = mislabel(mislabel_fraction, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNN PCA\n",
    "\n",
    "num_components_range = range(1, max_num_components)\n",
    "\n",
    "KNN_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in tqdm(num_components_range):\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    KNN_pipeline = make_pipeline(PCA(n_components=n_components), KNeighborsClassifier(n_neighbors=5))\n",
    "    # Kanske borde göras så att den kör cross validation på korrekt data?\n",
    "    KNN_scores = cross_val_score(KNN_pipeline, X_train, y_train_noise, cv=5)\n",
    "    KNN_mean_score = KNN_scores.mean()\n",
    "\n",
    "    #KNN_mean_scores.append(KNN_mean_score)\n",
    "\n",
    "KNN_optimal_n_components = num_components_range[KNN_mean_scores.index(max(KNN_mean_scores))]\n",
    "cross_val_err = 1 - max(KNN_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of PCA components with mislabels:\", KNN_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=KNN_optimal_n_components), KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train_noise)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##KNN features\n",
    "num_features = range(1, 30)\n",
    "KNN_mean_scores = []\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for k in num_features:\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    KNN_scores = cross_val_score(model, X_train_selected, y_train_noise, cv=5)\n",
    "    KNN_mean_score = KNN_scores.mean()\n",
    "\n",
    "    KNN_mean_scores.append(KNN_mean_score)\n",
    "\n",
    "KNN_optimal_k_features = num_features[KNN_mean_scores.index(max(KNN_mean_scores))]\n",
    "cross_val_err = 1 - max(KNN_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of features:\", KNN_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=KNN_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train_noise)\n",
    "model.fit(X_train_selected, y_train_noise)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features with noise:\", selected_features)\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC PCA\n",
    "\n",
    "SVC_mean_scores = []\n",
    "\n",
    "num_components_range = range(1, 25)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in num_components_range:\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    SVC_pipeline = make_pipeline(PCA(n_components=n_components), SVC())\n",
    "    \n",
    "    SVC_scores = cross_val_score(SVC_pipeline, X_train, y_train_noise, cv=5)\n",
    "    SVC_mean_score = SVC_scores.mean()\n",
    "\n",
    "    SVC_mean_scores.append(SVC_mean_score)\n",
    "\n",
    "SVC_optimal_n_components = num_components_range[SVC_mean_scores.index(max(SVC_mean_scores))]\n",
    "cross_val_err = 1 - max(SVC_mean_scores)\n",
    "\n",
    "print(\"SVC optimal number of PCA components:\", SVC_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=SVC_optimal_n_components), SVC())\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train_noise)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SVC features\n",
    "num_features = range(1, 50)\n",
    "SVC_mean_scores = []\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for k in num_features:\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train_noise)\n",
    "    \n",
    "    model = SVC()\n",
    "    \n",
    "    SVC_scores = cross_val_score(model, X_train_selected, y_train_noise, cv=5)\n",
    "    SVC_mean_score = SVC_scores.mean()\n",
    "\n",
    "    SVC_mean_scores.append(SVC_mean_score)\n",
    "\n",
    "SVC_optimal_k_features = num_features[SVC_mean_scores.index(max(SVC_mean_scores))]\n",
    "cross_val_err = 1 - max(SVC_mean_scores)\n",
    "\n",
    "print(\"SVC optimal number of features:\", SVC_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=SVC_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train_noise)\n",
    "model.fit(X_train_selected, y_train_noise)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Logistic regression PCA\n",
    "\n",
    "LR_mean_scores = []\n",
    "\n",
    "num_components_range = range(1, 25)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in num_components_range:\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    LR_pipeline = make_pipeline(PCA(n_components=n_components), LogisticRegression(random_state=16, max_iter=10000))\n",
    "    \n",
    "    LR_scores = cross_val_score(LR_pipeline, X_train, y_train_noise, cv=5)\n",
    "    LR_mean_score = LR_scores.mean()\n",
    "\n",
    "    LR_mean_scores.append(LR_mean_score)\n",
    "\n",
    "LR_optimal_n_components = num_components_range[LR_mean_scores.index(max(LR_mean_scores))]\n",
    "cross_val_err = 1 - max(LR_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of PCA components:\", LR_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=LR_optimal_n_components), LogisticRegression(random_state=16, max_iter=10000))\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train_noise)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Logistic Regression features\n",
    "num_features = range(1, 30)\n",
    "LR_mean_scores = []\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for k in num_features:\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train_noise)\n",
    "    \n",
    "    model = LogisticRegression(random_state=16, max_iter=10000)\n",
    "    \n",
    "    LR_scores = cross_val_score(model, X_train_selected, y_train_noise, cv=5)\n",
    "    LR_mean_score = LR_scores.mean()\n",
    "\n",
    "    LR_mean_scores.append(LR_mean_score)\n",
    "\n",
    "LR_optimal_k_features = num_features[LR_mean_scores.index(max(LR_mean_scores))]\n",
    "cross_val_err = 1 - max(LR_mean_scores)\n",
    "\n",
    "print(\"LR optimal number of features:\", LR_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=LR_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train_noise)\n",
    "model.fit(X_train_selected, y_train_noise)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
