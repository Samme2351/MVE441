{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#features = [f\"V{x}\" for x in range(1,2000)]\n",
    "df = pd.read_csv('Data/TCGAdata.txt', sep=\" \" ,header=0)\n",
    "labels_df = pd.read_csv('Data/TCGAlabels', sep=\" \" ,header=0)\n",
    "\n",
    "#Standardizing the rows (transposing as fit_transform standardizes along columns)\n",
    "scaled_df = pd.DataFrame(np.transpose(scaler.fit_transform(df.transpose())), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Range of PCA-components\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, labels_df.values.ravel(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 24/24 [02:57<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN optimal number of PCA components: 23\n",
      "Cross val err:  0.006063423200082574\n",
      "Train err:  0.0047639670853183436\n",
      "Test err:  0.01211072664359858\n"
     ]
    }
   ],
   "source": [
    "##KNN PCA\n",
    "\n",
    "max_num_components = 25\n",
    "num_components_range = range(1, max_num_components)\n",
    "\n",
    "KNN_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in tqdm(num_components_range):\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    KNN_pipeline = make_pipeline(PCA(n_components=n_components), KNeighborsClassifier(n_neighbors=5))\n",
    "    \n",
    "    KNN_scores = cross_val_score(KNN_pipeline, X_train, y_train, cv=5)\n",
    "    KNN_mean_score = KNN_scores.mean()\n",
    "\n",
    "    #KNN_mean_scores.append(KNN_mean_score)\n",
    "    KNN_mean_scores[n_components] = KNN_mean_score\n",
    "    \n",
    "KNN_optimal_n_components = np.where(KNN_mean_scores==KNN_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(KNN_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of PCA components:\", KNN_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=KNN_optimal_n_components), KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/29 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     KNN_scores \u001b[38;5;241m=\u001b[39m cross_val_score(model, X_train_selected, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     17\u001b[0m     KNN_mean_score \u001b[38;5;241m=\u001b[39m KNN_scores\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mKNN_mean_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(KNN_mean_score)\n\u001b[1;32m     21\u001b[0m KNN_optimal_k_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(KNN_mean_scores\u001b[38;5;241m==\u001b[39mKNN_mean_scores\u001b[38;5;241m.\u001b[39mmax())[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m cross_val_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmax\u001b[39m(KNN_mean_scores)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "##KNN features\n",
    "max_num_features = 30\n",
    "\n",
    "num_features = range(1, max_num_features)\n",
    "KNN_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "# Loop over different numbers of features\n",
    "for k in tqdm(num_features):\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    KNN_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "    KNN_mean_score = KNN_scores.mean()\n",
    "\n",
    "    #KNN_mean_scores.append(KNN_mean_score)\n",
    "\n",
    "KNN_optimal_k_features = np.where(KNN_mean_scores==KNN_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(KNN_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of features:\", KNN_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=KNN_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC optimal number of PCA components: 24\n",
      "Cross val err:  0.005197622334281782\n",
      "Train err:  0.0017323516673884987\n",
      "Test err:  0.01384083044982698\n"
     ]
    }
   ],
   "source": [
    "##SVC PCA\n",
    "\n",
    "SVC_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "#num_components_range = range(1, max_num_components)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in tqdm(num_components_range):\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    SVC_pipeline = make_pipeline(PCA(n_components=n_components), SVC())\n",
    "    \n",
    "    SVC_scores = cross_val_score(SVC_pipeline, X_train, y_train, cv=5)\n",
    "    SVC_mean_score = SVC_scores.mean()\n",
    "\n",
    "    #SVC_mean_scores.append(SVC_mean_score)\n",
    "\n",
    "SVC_optimal_n_components = np.where(SVC_mean_scores==SVC_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(SVC_mean_scores)\n",
    "\n",
    "print(\"SVC optimal number of PCA components:\", SVC_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=SVC_optimal_n_components), SVC())\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC optimal number of features: 43\n",
      "Most predictive features: Index(['V3', 'V18', 'V29', 'V64', 'V68', 'V87', 'V307', 'V308', 'V462', 'V475',\n",
      "       'V507', 'V539', 'V544', 'V627', 'V657', 'V687', 'V730', 'V803', 'V845',\n",
      "       'V1005', 'V1071', 'V1097', 'V1098', 'V1101', 'V1173', 'V1193', 'V1206',\n",
      "       'V1218', 'V1256', 'V1263', 'V1517', 'V1533', 'V1654', 'V1673', 'V1697',\n",
      "       'V1744', 'V1787', 'V1799', 'V1812', 'V1829', 'V1871', 'V1882', 'V1936'],\n",
      "      dtype='object')\n",
      "Cross val err:  0.007363063545276161\n",
      "Train err:  0.004330879168471191\n",
      "Test err:  0.01211072664359858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusmoller/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##SVC features\n",
    "max_num_features = 50\n",
    "num_features = range(1, max_num_features)\n",
    "SVC_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for k in tqdm(num_features):\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    \n",
    "    model = SVC()\n",
    "    \n",
    "    SVC_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "    SVC_mean_score = SVC_scores.mean()\n",
    "\n",
    "    #SVC_mean_scores.append(SVC_mean_score)\n",
    "\n",
    "SVC_optimal_k_features = np.where(SVC_mean_scores==SVC_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(SVC_mean_scores)\n",
    "\n",
    "print(\"SVC optimal number of features:\", SVC_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=SVC_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN optimal number of PCA components: 18\n",
      "Cross val err:  0.005198561380773903\n",
      "Train err:  0.0\n",
      "Test err:  0.00519031141868509\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression PCA\n",
    "\n",
    "LR_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "#num_components_range = range(1, 25)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in tqdm(num_components_range):\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    LR_pipeline = make_pipeline(PCA(n_components=n_components), LogisticRegression(random_state=16, max_iter=10000))\n",
    "    \n",
    "    LR_scores = cross_val_score(LR_pipeline, X_train, y_train, cv=5)\n",
    "    LR_mean_score = LR_scores.mean()\n",
    "\n",
    "    #LR_mean_scores.append(LR_mean_score)\n",
    "\n",
    "LR_optimal_n_components = np.where(LR_mean_scores==LR_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(LR_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of PCA components:\", LR_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=LR_optimal_n_components), LogisticRegression(random_state=16, max_iter=10000))\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR optimal number of features: 28\n",
      "Most predictive features: Index(['V18', 'V68', 'V462', 'V507', 'V539', 'V627', 'V657', 'V687', 'V730',\n",
      "       'V803', 'V845', 'V1005', 'V1071', 'V1098', 'V1101', 'V1193', 'V1256',\n",
      "       'V1533', 'V1654', 'V1673', 'V1744', 'V1787', 'V1799', 'V1812', 'V1829',\n",
      "       'V1871', 'V1882', 'V1936'],\n",
      "      dtype='object')\n",
      "Cross val err:  0.016894385441023063\n",
      "Train err:  0.0038977912516240387\n",
      "Test err:  0.02422145328719727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusmoller/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Logistic Regression features\n",
    "max_num_features = 30\n",
    "num_features = range(1, max_num_features)\n",
    "LR_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for k in tqdm(num_features):\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    \n",
    "    model = LogisticRegression(random_state=16, max_iter=10000)\n",
    "    \n",
    "    LR_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "    LR_mean_score = LR_scores.mean()\n",
    "\n",
    "    #LR_mean_scores.append(LR_mean_score)\n",
    "\n",
    "LR_optimal_k_features = np.where(LR_mean_scores==LR_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(LR_mean_scores)\n",
    "\n",
    "print(\"LR optimal number of features:\", LR_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=LR_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Part 2 Theme 2 mislabeling\n",
    "\n",
    "mislabel_fraction = 0.2\n",
    "labels = set(labels_df[\"x\"])\n",
    "\n",
    "num_samples = len(y_train)\n",
    "num_mislabels = int(mislabel_fraction * num_samples)\n",
    "mislabel_indices = np.random.choice(num_samples, num_mislabels, replace=False)\n",
    "\n",
    "y_train_noise = y_train.copy()\n",
    "\n",
    "for i in mislabel_indices:\n",
    "    correct = y_train[i]\n",
    "    y_train_noise[i] = np.random.choice(list(labels - set([correct])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN optimal number of PCA components with mislabels: 6\n",
      "Cross val err:  0.21914903606877567\n",
      "Train err:  0.03508012126461668\n",
      "Test err:  0.03633217993079585\n"
     ]
    }
   ],
   "source": [
    "##KNN PCA\n",
    "\n",
    "num_components_range = range(1, max_num_components)\n",
    "\n",
    "KNN_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in tqdm(num_components_range):\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    KNN_pipeline = make_pipeline(PCA(n_components=n_components), KNeighborsClassifier(n_neighbors=5))\n",
    "    # Kanske borde göras så att den kör cross validation på korrekt data?\n",
    "    KNN_scores = cross_val_score(KNN_pipeline, X_train, y_train_noise, cv=5)\n",
    "    KNN_mean_score = KNN_scores.mean()\n",
    "\n",
    "    #KNN_mean_scores.append(KNN_mean_score)\n",
    "\n",
    "KNN_optimal_n_components = num_components_range[KNN_mean_scores.index(max(KNN_mean_scores))]\n",
    "cross_val_err = 1 - max(KNN_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of PCA components with mislabels:\", KNN_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=KNN_optimal_n_components), KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train_noise)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN optimal number of features: 28\n",
      "Most predictive features with noise: Index(['V3', 'V18', 'V68', 'V87', 'V289', 'V350', 'V475', 'V494', 'V507',\n",
      "       'V539', 'V627', 'V1097', 'V1101', 'V1193', 'V1218', 'V1256', 'V1263',\n",
      "       'V1517', 'V1533', 'V1549', 'V1654', 'V1673', 'V1744', 'V1787', 'V1799',\n",
      "       'V1846', 'V1882', 'V1936'],\n",
      "      dtype='object')\n",
      "Cross val err:  0.22478049788245025\n",
      "Train err:  0.029449978345604144\n",
      "Test err:  0.02941176470588236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusmoller/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###KNN features\n",
    "max_num_features = 30\n",
    "\n",
    "num_features = range(1, max_num_features)\n",
    "KNN_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "# Loop over different numbers of features\n",
    "for k in tqdm(num_features):\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    \n",
    "    KNN_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "    KNN_mean_score = KNN_scores.mean()\n",
    "\n",
    "    #KNN_mean_scores.append(KNN_mean_score)\n",
    "\n",
    "KNN_optimal_k_features = np.where(KNN_mean_scores==KNN_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(KNN_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of features:\", KNN_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=KNN_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC optimal number of PCA components: 9\n",
      "Cross val err:  0.2048586265506006\n",
      "Train err:  0.005197055002165385\n",
      "Test err:  0.01730103806228378\n"
     ]
    }
   ],
   "source": [
    "##SVC PCA\n",
    "\n",
    "SVC_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "#num_components_range = range(1, max_num_components)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in tqdm(num_components_range):\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    SVC_pipeline = make_pipeline(PCA(n_components=n_components), SVC())\n",
    "    \n",
    "    SVC_scores = cross_val_score(SVC_pipeline, X_train, y_train, cv=5)\n",
    "    SVC_mean_score = SVC_scores.mean()\n",
    "\n",
    "    #SVC_mean_scores.append(SVC_mean_score)\n",
    "\n",
    "SVC_optimal_n_components = np.where(SVC_mean_scores==SVC_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(SVC_mean_scores)\n",
    "\n",
    "print(\"SVC optimal number of PCA components:\", SVC_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=SVC_optimal_n_components), SVC())\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC optimal number of features: 49\n",
      "Most predictive features: Index(['V3', 'V18', 'V68', 'V87', 'V217', 'V289', 'V307', 'V308', 'V350',\n",
      "       'V462', 'V475', 'V494', 'V507', 'V539', 'V568', 'V627', 'V673', 'V687',\n",
      "       'V803', 'V845', 'V855', 'V982', 'V1033', 'V1066', 'V1097', 'V1098',\n",
      "       'V1101', 'V1102', 'V1193', 'V1218', 'V1256', 'V1263', 'V1478', 'V1517',\n",
      "       'V1533', 'V1549', 'V1654', 'V1673', 'V1697', 'V1744', 'V1787', 'V1799',\n",
      "       'V1812', 'V1829', 'V1846', 'V1871', 'V1882', 'V1936', 'V1971'],\n",
      "      dtype='object')\n",
      "Cross val err:  0.21049008836427496\n",
      "Train err:  0.00822867042009523\n",
      "Test err:  0.01903114186851207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusmoller/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##SVC features\n",
    "max_num_features = 50\n",
    "num_features = range(1, max_num_features)\n",
    "SVC_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for k in tqdm(num_features):\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    \n",
    "    model = SVC()\n",
    "    \n",
    "    SVC_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "    SVC_mean_score = SVC_scores.mean()\n",
    "\n",
    "    #SVC_mean_scores.append(SVC_mean_score)\n",
    "\n",
    "SVC_optimal_k_features = np.where(SVC_mean_scores==SVC_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(SVC_mean_scores)\n",
    "\n",
    "print(\"SVC optimal number of features:\", SVC_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=SVC_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN optimal number of PCA components: 23\n",
      "Cross val err:  0.2052934050764853\n",
      "Train err:  0.00606323083585969\n",
      "Test err:  0.01557093425605538\n"
     ]
    }
   ],
   "source": [
    "##Logistic regression PCA\n",
    "\n",
    "LR_mean_scores = np.zeros(max_num_components)\n",
    "\n",
    "#num_components_range = range(1, 25)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for n_components in tqdm(num_components_range):\n",
    "    \n",
    "    #PCA\n",
    "\n",
    "    LR_pipeline = make_pipeline(PCA(n_components=n_components), LogisticRegression(random_state=16, max_iter=10000))\n",
    "    \n",
    "    LR_scores = cross_val_score(LR_pipeline, X_train, y_train, cv=5)\n",
    "    LR_mean_score = LR_scores.mean()\n",
    "\n",
    "    #LR_mean_scores.append(LR_mean_score)\n",
    "\n",
    "LR_optimal_n_components = np.where(LR_mean_scores==LR_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(LR_mean_scores)\n",
    "\n",
    "print(\"KNN optimal number of PCA components:\", LR_optimal_n_components)\n",
    "\n",
    "opt_pipeline = make_pipeline(PCA(n_components=LR_optimal_n_components), LogisticRegression(random_state=16, max_iter=10000))\n",
    "\n",
    "opt_pipeline.fit(X_train, y_train)\n",
    "train_pred = opt_pipeline.predict(X_train)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = opt_pipeline.predict(X_test)\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR optimal number of features: 26\n",
      "Most predictive features: Index(['V3', 'V18', 'V68', 'V87', 'V289', 'V475', 'V507', 'V539', 'V627',\n",
      "       'V1097', 'V1101', 'V1193', 'V1218', 'V1256', 'V1263', 'V1517', 'V1533',\n",
      "       'V1549', 'V1654', 'V1673', 'V1744', 'V1787', 'V1799', 'V1846', 'V1882',\n",
      "       'V1936'],\n",
      "      dtype='object')\n",
      "Cross val err:  0.22435041458902627\n",
      "Train err:  0.025119099177132953\n",
      "Test err:  0.02941176470588236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusmoller/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Logistic Regression features\n",
    "max_num_features = 30\n",
    "num_features = range(1, max_num_features)\n",
    "LR_mean_scores = np.zeros(max_num_features)\n",
    "\n",
    "# Loop over different numbers of components\n",
    "for k in tqdm(num_features):\n",
    "    \n",
    "    feature_selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    \n",
    "    model = LogisticRegression(random_state=16, max_iter=10000)\n",
    "    \n",
    "    LR_scores = cross_val_score(model, X_train_selected, y_train, cv=5)\n",
    "    LR_mean_score = LR_scores.mean()\n",
    "\n",
    "    #LR_mean_scores.append(LR_mean_score)\n",
    "\n",
    "LR_optimal_k_features = np.where(LR_mean_scores==LR_mean_scores.max())[0][0]+1\n",
    "cross_val_err = 1 - max(LR_mean_scores)\n",
    "\n",
    "print(\"LR optimal number of features:\", LR_optimal_k_features)\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=LR_optimal_k_features)\n",
    "X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the most predictive features\n",
    "selected_features = X_train.columns[selected_feature_indices]\n",
    "print(\"Most predictive features:\", selected_features)\n",
    "\n",
    "train_pred = model.predict(X_train_selected)\n",
    "train_error = 1 - accuracy_score(y_train, train_pred)\n",
    "\n",
    "test_pred = model.predict(X_test[X_test.columns[selected_feature_indices]])\n",
    "test_error = 1 - accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(\"Cross val err: \", cross_val_err)\n",
    "print(\"Train err: \", train_error)\n",
    "print(\"Test err: \", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
